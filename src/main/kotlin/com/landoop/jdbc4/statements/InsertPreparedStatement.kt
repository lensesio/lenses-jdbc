package com.landoop.jdbc4.statements

import com.landoop.jdbc4.AvroSchemaParameterMetaData
import com.landoop.jdbc4.Constants
import com.landoop.jdbc4.resultset.EmptyResultSetMetaData
import com.landoop.jdbc4.util.Logging
import com.landoop.jdbc4.RecordBuilder
import com.landoop.jdbc4.client.RestClient
import com.landoop.jdbc4.client.domain.InsertRecord
import com.landoop.jdbc4.client.domain.PreparedInsertInfo
import com.landoop.jdbc4.resultset.emptyResultSet
import java.sql.Connection
import java.sql.ParameterMetaData
import java.sql.PreparedStatement
import java.sql.ResultSet
import java.sql.ResultSetMetaData
import java.sql.SQLException

/**
 * An implementation of [PreparedStatement] that executes an insert query.
 */
class InsertPreparedStatement(private val conn: Connection,
                              private val client: RestClient,
                              sql: String) : AbstractPreparedStatement, Logging {

  override fun getUpdateCount(): Int = 1

  override fun getResultSet(): ResultSet = TODO()

  override fun getQueryTimeout(): Int = client.connectionRequestTimeout()
  override fun setQueryTimeout(seconds: Int) = throw UnsupportedOperationException()

  // for a prepared statement we need to connect to the lenses server, as the parsing
  // of the SQL will take place on the server side
  // The server will return back to us an object containing the required details of the
  // topic name, parameters, schema etc.
  private val info: PreparedInsertInfo = client.prepareStatement(sql).let {
    it.info ?: throw SQLException(it.error ?: "No error info available")
  }

  // the last resultset generated by this statement
  private var rs: ResultSet = emptyResultSet

  // holder for values currently being built up
  private var builder = RecordBuilder(info)

  // holds all the records for a batch, should be cleared between batches
  private val batch = mutableListOf<InsertRecord>()


  private fun setValue(k: Int, value: Any?) = builder.put(k, value)

  /**
   * Clears the current parameter values immediately.
   * That is, the current record that is being "built" will be reset to empty.
   */
  override fun clearParameters() {
    builder = RecordBuilder(info)
  }

  private fun dispatchRecord() {
    builder.checkRecord()
    client.executePreparedInsert(info.topic, info.keyType, info.valueType, listOf(builder.build()))
  }

  override fun getConnection(): Connection = conn

  override fun execute(): Boolean {
    dispatchRecord()
    return true
  }

  override fun executeUpdate(): Int {
    dispatchRecord()
    // this method returns 1 because executeUpdate() always sends only a single insert statement
    // if we want to send multiple we use executeBatch()
    return 1
  }

  // -- meta data methods

  /**
   * @return an empty result set because we do not yet support prepared statements for queries
   */
  override fun getMetaData(): ResultSetMetaData = EmptyResultSetMetaData

  override fun getParameterMetaData(): ParameterMetaData = AvroSchemaParameterMetaData(info)

  // -- batching support

  // returns the current batch size
  fun batchSize(): Int = batch.size

  // adds the current record to the batch
  override fun addBatch() {
    builder.checkRecord()
    if (batch.size == Constants.BATCH_HARD_LIMIT)
      throw SQLException("Batch size would exceed maximum of ${Constants.BATCH_HARD_LIMIT}")
    batch.add(builder.build())
    // we don't clear the builder here as parameters should remain in force for the next record
  }

  override fun clearBatch() {
    batch.clear()
  }

  override fun executeBatch(): IntArray {
    logger.debug("Executing batch of ${batch.size} records")
    client.executePreparedInsert(info.topic, info.keyType, info.valueType, batch.toList())
    // we should return an array of update counts, but we are only inserting, so we return an array of 0s
    val size = batch.size
    return IntArray(size) { 0 }
  }

  override fun executeQuery(): ResultSet = TODO()
}

